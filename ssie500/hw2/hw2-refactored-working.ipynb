{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import requests as r\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/grantaguinaldo/mcmc/master/pride_prejudice.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(url):\n",
    "    string_punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~‘êàé—’”“'\n",
    "    url = url\n",
    "    data = r.get(url)\n",
    "    f = data.text\n",
    "    print('Text File Has Been Downloaded')\n",
    "    remove_bom = f.replace('\\ufeff', '###')\n",
    "    comma_delimit = remove_bom.replace('\\n', ',').strip().lower().replace('\\r', '').split(',') \n",
    "    clean_text = [each for each in comma_delimit if (str.rstrip(each) != '') or\\\n",
    "                  (str.rstrip(each) not in string_punctuation)]\n",
    "    return pd.DataFrame({'text': clean_text})\n",
    "\n",
    "def clean(s):\n",
    "    '''\n",
    "    Remove punctuation, numeric values and all extra spaces from string. \n",
    "    '''\n",
    "    string_punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~‘êàé—’”“'\n",
    "    # remove punctuation\n",
    "    no_punc = s.translate(str.maketrans('', '', string_punctuation))\n",
    "    # remove num\n",
    "    no_num = ''.join([each for each in no_punc if not each.isdigit()])\n",
    "    # remove extra spaces\n",
    "    return ' '.join(no_num.split())\n",
    "\n",
    "\n",
    "def count_alpha(x):\n",
    "    return Counter(x)\n",
    "\n",
    "def count(s):\n",
    "    count_a = s.count('a') \n",
    "    count_b = s.count('b')\n",
    "    count_c = s.count('c')\n",
    "    count_d = s.count('d')\n",
    "    count_e = s.count('e')\n",
    "    count_f = s.count('f')\n",
    "    count_g = s.count('g')\n",
    "    count_h = s.count('h')\n",
    "    count_i = s.count('i')\n",
    "    count_j = s.count('j')\n",
    "    count_k = s.count('k')\n",
    "    count_l = s.count('l')\n",
    "    count_m = s.count('m')\n",
    "    count_n = s.count('n')\n",
    "    count_o = s.count('o')\n",
    "    count_p = s.count('p')\n",
    "    count_q = s.count('q')\n",
    "    count_r = s.count('r')\n",
    "    count_s = s.count('s')\n",
    "    count_t = s.count('t')\n",
    "    count_u = s.count('u')\n",
    "    count_v = s.count('v')\n",
    "    count_w = s.count('w')\n",
    "    count_x = s.count('x')\n",
    "    count_y = s.count('y')\n",
    "    count_z = s.count('z')\n",
    "    count_space = s.count(' ')\n",
    "    \n",
    "    return {'a': count_a, 'b': count_b, 'c': count_c, 'd': count_d, 'e': count_e,\n",
    "            'f': count_f, 'g': count_g, 'h': count_h, 'i': count_i, 'j': count_j,\n",
    "            'k': count_k, 'l': count_l, 'm': count_m, 'n': count_n, 'o': count_o,\n",
    "            'p': count_p, 'q': count_q, 'r': count_r, 's': count_s, 't': count_t,\n",
    "            'u': count_u, 'v': count_v, 'w': count_w, 'x': count_x, 'y': count_y,\n",
    "            'z': count_z, 'space': count_space}\n",
    "\n",
    "def markov(s):\n",
    "    return markov_pred_dict[s]\n",
    "\n",
    "def markov_sampler(char_init, n_iter, markov_dict):\n",
    "    char_now = char_init\n",
    "    markov_str = []\n",
    "    n_iter = n_iter\n",
    "    for i in range(n_iter):\n",
    "        char_now = markov(char_now)\n",
    "        markov_str.append(char_now)\n",
    "    return ''.join(markov_str)\n",
    "\n",
    "def generate_kgram(s, n):\n",
    "    return Counter([s[i:i+n] for i in range(0, len(s), 1)])\n",
    "\n",
    "def graph(x, y, data, ylabel, xlabel, title):\n",
    "    sns.set(rc={'figure.figsize':(15,5)})\n",
    "    sns.barplot(x=x, y=y, data=data)\n",
    "    plt.ylabel(ylabel, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=16)\n",
    "    plt.ylim(0, 0.180, 0.025)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(title, fontsize=17)\n",
    "    return plt.show()\n",
    "\n",
    "idx_list = ['space', 'a', 'b', 'c', \n",
    "            'd', 'e', 'f', 'g', 'h', \n",
    "            'i', 'j', 'k', 'l', 'm', \n",
    "            'n', 'o', 'p', 'q', 'r', \n",
    "            's', 't', 'u', 'v', 'w', \n",
    "            'x', 'y', 'z']\n",
    "\n",
    "new_col_list = ['first_pos', ' ', 'a', 'b', 'c',\n",
    "                'd', 'e', 'f', 'g', 'h', 'i',\n",
    "                'j', 'k', 'l', 'm', 'n', 'o',\n",
    "                'p', 'q', 'r', 's', 't', 'u',\n",
    "                'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "idx_list_2 = ['first_pos', 'a', 'b', 'c', \n",
    "            'd', 'e', 'f', 'g', 'h', \n",
    "            'i', 'j', 'k', 'l', 'm', \n",
    "            'n', 'o', 'p', 'q', 'r', \n",
    "            's', 't', 'u', 'v', 'w', \n",
    "            'x', 'y', 'z']\n",
    "\n",
    "df = load_data(url)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = copy.deepcopy(df)\n",
    "df_clean.loc[:, 'clean_string'] = df_clean['text'].apply(clean)\n",
    "df_clean.replace('', np.nan, inplace=True)\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[~df_clean['clean_string'].isna()]\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[:, 'clean_string_count'] = df_clean['clean_string'].apply(count_alpha)\n",
    "df_clean.loc[:, 'clean_string_count_py'] = df_clean['clean_string'].apply(count)\n",
    "\n",
    "list_dict = [dict(each) for each in df_clean.clean_string_count.tolist()]\n",
    "final_dist = {}\n",
    "for d in list_dict:\n",
    "    for k in d.keys():\n",
    "        final_dist[k] = final_dist.get(k, 0) + d[k]\n",
    "\n",
    "list_dict_py = [dict(each) for each in df_clean.clean_string_count_py.tolist()]\n",
    "final_dist_py = {}\n",
    "for d in list_dict_py:\n",
    "    for k in d.keys():\n",
    "        final_dist_py[k] = final_dist_py.get(k, 0) + d[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df_freq\n",
    "\n",
    "df_freq = pd.DataFrame(final_dist.items(), columns=['letter', 'count'])\n",
    "df_freq['freq'] = df_freq['count'] / df_freq['count'].sum()\n",
    "df_freq.at[3, 'letter'] = 'space'\n",
    "df_freq.sort_values(by='count', ascending=False, inplace=True)\n",
    "df_freq.reset_index(drop=True, inplace=True)\n",
    "df_freq['rank'] = df_freq.index + 1\n",
    "\n",
    "# Create df_freq_py\n",
    "\n",
    "df_freq_py = pd.DataFrame(final_dist_py.items(), columns=['letter', 'count'])\n",
    "df_freq_py['freq'] = df_freq_py['count'] / df_freq_py['count'].sum()\n",
    "#df_freq_py.at[3, 'letter'] = 'space'\n",
    "df_freq_py.sort_values(by='count', ascending=False, inplace=True)\n",
    "df_freq_py.reset_index(drop=True, inplace=True)\n",
    "df_freq_py['rank'] = df_freq_py.index + 1\n",
    "\n",
    "# Check if both df are the same\n",
    "df_freq_py.equals(df_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph(x='letter', \n",
    "      y='freq', \n",
    "      data=df_freq, \n",
    "      ylabel='Count \\n Frequency', \n",
    "      xlabel='Letter', \n",
    "      title='Distrubution of Letters in Pride and Prejudice by \\n Jane Austen (Using Counter)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[:, 'kgrams'] = df_clean['clean_string'].apply(generate_kgram, args=[2])\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgram_list_dict_py = [dict(each) for each in df_clean.kgrams.tolist()]\n",
    "kgram_dist= {}\n",
    "for d in kgram_list_dict_py:\n",
    "    for k in d.keys():\n",
    "        kgram_dist[k] = kgram_dist.get(k, 0) + d[k]\n",
    "        \n",
    "df_kgram = pd.DataFrame(kgram_dist.items(), columns=['kgram', 'count'])\n",
    "df_kgram['kgram_len'] = df_kgram['kgram'].str.split(' ').str.len()\n",
    "two_grams = df_kgram[df_kgram.kgram_len == 1]\n",
    "\n",
    "two_grams = copy.deepcopy(two_grams)\n",
    "\n",
    "two_grams.loc[:, 'first_pos'] = two_grams['kgram'].str[0]\n",
    "two_grams.loc[:, 'second_pos'] = two_grams['kgram'].str[1]\n",
    "\n",
    "df = two_grams[['kgram', 'count', 'first_pos', 'second_pos']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df.pivot_table(index=['first_pos'], columns='second_pos', values='count')\n",
    "df_trans['first_pos'] = df_trans.index\n",
    "df_trans.reset_index(drop=True, inplace=True)\n",
    "df_reorder = df_trans.reindex(columns=idx_list_2)\n",
    "df_reorder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reorder['idxmax'] = df_reorder.iloc[:, 1:-1].idxmax(axis=1)\n",
    "markov_pred_dict = dict(zip(df_reorder['first_pos'].tolist(), df_reorder['idxmax'].tolist()))\n",
    "markov_pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_string = markov_sampler(char_init='t', n_iter=3000, markov_dict=markov_pred_dict)\n",
    "markov_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kgram = copy.deepcopy(df_kgram)\n",
    "df_kgram.loc[:, 'first_pos'] = df_kgram['kgram'].str[0]\n",
    "df_kgram.loc[:, 'second_pos'] = df_kgram['kgram'].str[1]\n",
    "df_k = df_kgram[['kgram', 'count', 'first_pos', 'second_pos']]\n",
    "df_ktrans = df_k.pivot_table(index=['first_pos'], columns='second_pos', values='count')\n",
    "df_ktrans['first_pos'] = df_ktrans.index\n",
    "df_ktrans.reset_index(drop=True, inplace=True)\n",
    "df_ktrans.fillna(0, inplace=True) \n",
    "\n",
    "df_ktrans = df_ktrans.reindex(columns=new_col_list).fillna(0)\n",
    "df_ktrans.rename(columns={' ': 'space'}, inplace=True)\n",
    "df_ktrans.loc[0, 'first_pos'] = 'space'\n",
    "df_ktrans['total'] = df_ktrans.iloc[:, 0:].sum(axis=1)\n",
    "df_ktrans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktrans_freq = df_ktrans.iloc[:, 1:].div(df_ktrans['total'] , axis=0)\n",
    "df_ktrans_freq_2 = df_ktrans_freq.iloc[:, 0:27]\n",
    "df_ktrans_freq_2['idx'] = idx_list\n",
    "df_ktrans_freq_2.set_index('idx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(17,8)})\n",
    "sns.heatmap(df_ktrans_freq_2.iloc[:, 0:27], linewidths=2, yticklabels=1, cmap='Blues')\n",
    "plt.ylabel('First Position', fontsize=14)\n",
    "plt.xlabel('Second Position', fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.title('Markov Transistion Frequency Between Two Letters \\n', fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
